PMID,Titulo,Autores,Año de Publicacion,Población estudiada,Método de DL usado,"Datos emocionales usados (facial, voz, texto)",Emociones descritas,Técnicas de IA utilizadas,Base de datos,Árbol de emociones,Resultados principales,Limitaciones,Estado
33380334,Stress detection using deep neural networks,"Li R, Liu Z.",2020,Humano,red neuronal convolucional unidimensional y una red neuronal de perceptrón multicapa,"señales fisiológicas (sensores adheridos al cuerpo humano: electrocardiograma, actividad electrodermal, electromiografía, temperatura de la piel, frecuencia respiratoria y datos de acelerómetro de 3 ejes p. 3 p. 4)",estres y las emociones clasificadas que se miden no se mencionan explícitamente,"DL, ML, redes neuronales","conjunto de datos WESAD (""Detección de Estrés y Afecto Portátil"") disponible públicamente en el Repositorio de Aprendizaje Automático de la Universidad de California en Irvine p. 10. Y datos de investigaciones previas",No,"1. Los métodos tradicionales de aprendizaje automático para la detección de estrés utilizando señales fisiológicas han mostrado resultados mixtos, con una precisión que oscila entre el 50% y el 90% p. 1.
2. El estudio desarrolló dos redes neuronales profundas, una red neuronal convolucional 1D profunda y una red neuronal perceptrón multicapa profunda, que superaron significativamente a los algoritmos tradicionales de aprendizaje automático tanto para la detección binaria de estrés como para las tareas de clasificación de emociones de 3 clases p. 9.
3. La investigación demostró el potencial de las redes neuronales profundas para desarrollar métodos robustos, continuos y no invasivos para la detección de estrés y la clasificación de emociones, con el objetivo de mejorar la calidad de vida p. 9.","1. el conjunto de datos relativamente pequeño utilizado (solo 15 personas)
2. el estudio reconoce la necesidad de futuras investigaciones para entrenar y probar las redes neuronales en conjuntos de datos más grandes y diversos, con el fin de mejorar su robustez y aplicabilidad a una gama más amplia de individuos p. 9",
37628493,DS-CNN: Deep Convolutional Neural Networks for Facial Emotion Detection in Children with Down Syndrome during Dolphin-Assisted Therapy,"Moreno Escobar JJ, Morales Matamoros O, Aguilar Del Villar EY, Quintana Espinosa H, Chanona Hernández L.",2023,niños con Síndrome de Down,"Red Neuronal Convolucional Profunda (Deep CNN o DS-CNN), y machine vision",imagenes (expresiones faciales) y electroencefalograma (EEG),"microexpresiones faciales: alegría, neutral, tristeza, sorpresa. atencion, calma, desagrado","DL, redes neuronales","Down’s Syndrome Dataset (DSDS), que contiene imágenes de las expresiones faciales de niños con Síndrome de Down.",No,"1. Efectividad del Reconocimiento de Emociones: Se desarrolló un modelo de reconocimiento de emociones utilizando redes neuronales convolucionales (CNN) que puede clasificar con alta precisión las emociones de los niños con Síndrome de Down durante la terapia asistida por delfines.
2. Mejora en la Personalización de la Terapia: Al comprender las respuestas emocionales de los niños, los terapeutas pueden adaptar las sesiones de terapia para satisfacer mejor las necesidades emocionales individuales, lo que potencialmente mejora los resultados terapéuticos.
3. Identificación de Patrones Emocionales: El estudio permite el monitoreo y seguimiento de las emociones a lo largo de las sesiones de terapia, lo que ayuda a identificar patrones o desencadenantes que pueden influir en el progreso del niño.
4. Contribución a un Entorno Terapéutico Empático: Al tener una mejor comprensión de las emociones de los niños con Síndrome de Down, se puede fomentar un ambiente terapéutico más solidario y empático, promoviendo su desarrollo emocional y crecimiento general.
5. Integración de Técnicas Avanzadas: La investigación combina técnicas de visión artificial y aprendizaje profundo, lo que representa un avance significativo en el campo del reconocimiento de emociones en poblaciones con dificultades de comunicación p2, 6, 20","1. Tamaño Limitado de la Base de Datos: El modelo fue entrenado con un conjunto de datos relativamente pequeño, lo que podría afectar la generalizabilidad de los resultados. Un tamaño de muestra limitado puede no capturar completamente la variabilidad en las expresiones faciales de los niños con Síndrome de Down durante la terapia.
2. Variabilidad en las Emociones: La diversidad en las respuestas emocionales de los niños puede no estar completamente representada en el conjunto de datos utilizado, lo que podría limitar la capacidad del modelo para reconocer todas las emociones de manera efectiva.
3. Falta de Comparaciones Directas: No se encontraron otros estudios que utilizaran el mismo conjunto de datos, lo que dificulta la comparación directa de los resultados y la validación del enfoque propuesto.
4. Desafíos en la Implementación en Tiempo Real: Aunque el modelo logra el reconocimiento de emociones en tiempo real, la implementación práctica en entornos terapéuticos puede enfrentar desafíos técnicos y logísticos que no se abordaron en el estudio.
5. Limitaciones en la Evaluación de Resultados: La evaluación de la efectividad del modelo se basa en un conjunto de datos de prueba que puede no reflejar completamente el rendimiento en situaciones del mundo real, donde las condiciones pueden variar significativamente p. 2 p.19 ",
27534393,25th Annual Computational Neuroscience Meeting: CNS-2016,"Sharpee TO, Destexhe A, Kawato M, Sekulić V, Skinner FK, Wójcik DK, Chintaluri C, Cserpán D, Somogyvári Z, Kim JK, Kilpatrick ZP, Bennett MR, Josić K, Elices I, Arroyo D, Levi R, Rodriguez FB, Varona P, Hwang E, Kim B, Han HB, Kim T, McKenna JT, Brown RE, McCarley RW, Choi JH, Rankin J, Popp PO, Rinzel J, Tabas A, Rupp A, Balaguer-Ballester E, Maturana MI, Grayden DB, Cloherty SL, Kameneva T, Ibbotson MR, Meffin H, Koren V, Lochmann T, Dragoi V, Obermayer K, Psarrou M, Schilstra M, Davey N, Torben-Nielsen B, Steuber V, Ju H, Yu J, Hines ML, Chen L, Yu Y, Kim J, Leahy W, Shlizerman E, Birgiolas J, Gerkin RC, Crook SM, Viriyopase A, Memmesheimer RM, Gielen S, Dabaghian Y, DeVito J, Perotti L, Kim AJ, Fenk LM, Cheng C, Maimon G, Zhao C, Widmer Y, Sprecher S, Senn W, Halnes G, Mäki-Marttunen T, Keller D, Pettersen KH, Andreassen OA, Einevoll GT, Yamada Y, Steyn-Ross ML, Alistair Steyn-Ross D, Mejias JF, Murray JD, Kennedy H, Wang XJ, Kruscha A, Grewe J, Benda J, Lindner B, Badel L, Ohta K, Tsuchimoto Y, Kazama H, Kahng B, Tam ND, Pollonini L, Zouridakis G, Soh J, Kim D, Yoo M, et al.",2016,"Humano (72 personas con esquizofrenia y 74 controles sanos), animales (ratones y primates) o no especifica",,,,,,No,,,"Excluido, recopilacion de resumenes de presentaciones en un congreso. No hay muchos datos concretos"
36298415,Kids' Emotion Recognition Using Various Deep-Learning Models with Explainable AI,"Rathod M, Dalvi C, Kaur K, Patil S, Gite S, Kamat P, Kotecha K, Abraham A, Gabralla LA.",2022,Niños (7 y 10 años),CNN,Imágenes y videos ,"Felicidad, tristeza, sorpresa, miedo, enojo, disgusto y neutral.","VGGNets, ResNets, DenseNets, InceptionV3, e InceptionResNetV2",LIRIS Children Spontaneous Facial Expression Video Database y un nuevo dataset creado por los autores.,No,"-Las CNN utilizadas lograron una alta precisión en la detección de emociones (ResNet152 V2 alcanzó hasta 89.31% en LIRIS y 90.98% en el dataset propio).
-Se usaron técnicas como Grad-CAM y ScoreCam para hacer más comprensible cómo las CNN detectan emociones a partir de características faciales", Desequilibrio en el conjunto de datos y variación en la duración de las expresiones.,
33074102,"On the objectivity, reliability, and validity of deep learning enabled bioimage analyses","Segebarth D, Griebel M, Stein N, von Collenberg CR, Martin C, Fiedler D, Comeras LB, Sah A, Schoeffler V, Lüffe T, Dürr A, Gupta R, Sasi M, Lillesaar C, Lange MD, Tasan RO, Singewald N, Pape HC, Flath CM, Blum R.",2020,Imágenes de bioimágenes de ratones y peces cebra,U-Net,Imágenes fluorescentes de tejidos para análisis de características celulares.,No se miden emociones,Redes neuronales,-,No,Uso de múltiples anotadores humanos para mayor objetividad y ensembles de modelos para mejorar la fiabilidad y validez del análisis.,Aplicabilidad limitada a otras tareas de segmentación más complejas; el enfoque se basó en la arquitectura U-Net exclusivamente.,
34105405,Deep learning techniques for automated detection of autism spectrum disorder based on thermal imaging,"Ganesh K, Umapathy S, Thanaraj Krishnan P.",2021,Niños con edades entre 5 y 10 años,CNN personalizada y ResNet-50.,Imágenes térmicas del rostro para medir la temperatura facial y evaluar emociones.,"Felicidad, enojo y tristeza",DL ,-,No,La CNN personalizada tuvo un 96% de precisión y ResNet-50 un 90%.,Se requiere un mayor conjunto de datos para mejorar la validación del modelo,
34469328,Emotional Analysis of Twitter Posts During the First Phase of the COVID-19 Pandemic in Greece: Infoveillance Study,"Geronikolou S, Drosatos G, Chrousos G.",2021,"Cualquier persona que haya publicado tweets en inglés relacionados con COVID-19 en ese periodo, sin distinción de edad.",RNN,Texto ,"Alegría, tristeza, disgusto, miedo, sorpresa y enojo",DL con redes neuronales ,Tweets recogidos a través de Twitter API con Social Feed Manager.,Clasificación de emociones básicas de Ekman.,"La emoción más frecuente fue sorpresa, seguida por enojo durante el confinamiento.",Restricción a emociones básicas y análisis centrado solo en la primera ola de la pandemia.,
36200082,Effect of Reading Activities on Children's Mental Health under the Environment of Artificial Intelligence and Deep Learning,Yang M.,2022,Niños,-,Textos,-,IA y DL,-,No,La lectura de libros ilustrados podría mejorar la salud mental de los niños,Los problemas éticos y metodológicos llevaron a la retracción del artículo,"Excluido, el artículo fue retractado, lo que significa que la confiabilidad de los datos y hallazgos no puede ser confirmada."
37870890,"Objectively Quantifying Pediatric Psychiatric Severity Using Artificial Intelligence, Voice Recognition Technology, and Universal Emotions: Pilot Study for Artificial Intelligence-Enabled Innovation to Address Youth Mental Health Crisis","Caulley D, Alemu Y, Burson S, Cárdenas Bautista E, Abebe Tadesse G, Kottmyer C, Aeschbach L, Cheungvivatpant B, Sezgin E.",2023,Niños y adolescentes,RNN,Voz,"ira, miedo, tristeza y felicidad","Gaussian Mixture Models, Expectation Maximization y Redes Neuronales Recurrentes (RNN).",-,No,"1. La detección automática de emociones a partir del habla de los pacientes mediante modelos de inteligencia artificial es factible 
2. El modelo basado en CNN demostró ser prometedor en la detección generalizada de emociones",Falta de análisis preliminar y justificación de métodos,
38319707,Capacity of Generative AI to Interpret Human Emotions From Visual and Textual Data: Pilot Evaluation Study,"Elyoseph Z, Refoua E, Asraf K, Lvovsky M, Shimoni Y, Hadar-Shoval D.",2024,Adultos (17 a 84 años),"Los de procesamiento de lenjuaje natural: uso de grandes modelos de lenguaje (LLMs) y modelos basados en transformadores, como Bidirectional Encoder Representations From Transformers (BERT) y Generative Pre-Trained Transformer (GPT)",imagen y texto,"Las señales emocionales y estados mentales medidos incluyeron una amplia gama de emociones como decepción, vergüenza, ansiedad, defensividad, dolor, malestar, responsabilidad, frustración y duelo, entre otros",ChatGPT-4 y Google Bard,-,No. pero discute la evaluación de las habilidades de los modelos de IA para interpretar emociones utilizando la Escala de Conciencia Emocional (LEAS) y el Test de Lectura de la Mente en los Ojos (RMET) ,"1. El estudio evaluó sistemáticamente la competencia de grandes modelos de lenguaje (LLMs), específicamente ChatGPT-4 y Google Bard, en tareas relacionadas con la mentalización utilizando métricas visuales y textuales p. 2.
2. ChatGPT-4 demostró respuestas no aleatorias en el Test de Lectura de la Mente en los Ojos (RMET), lo que indica su capacidad para interpretar señales emocionales a partir de expresiones faciales p. 4.
3. También se evaluó el rendimiento de Google Bard, y el estudio proporcionó información sobre sus capacidades y limitaciones en la interpretación de señales emocionales p. 5.
4. El estudio resaltó las percepciones matizadas sobre las capacidades de ChatGPT-4 y Google Bard, incluyendo su potencial integración en paradigmas de salud mental y las consideraciones éticas asociadas con su uso p. 7.
5. También se discutieron las limitaciones del estudio, incluyendo la naturaleza dinámica de los modelos, la naturaleza de ""caja negra"" de los modelos y las discrepancias lingüísticas en la comparación de puntuaciones obtenidas de poblaciones de habla inglesa y francesa p. 6.","1. El examen se realizó en modelos específicos en un momento particular, y futuras actualizaciones y versiones podrían arrojar resultados diferentes, reflejando la naturaleza dinámica de estos modelos p. 6.
2. Las pruebas elegidas miden efectivamente el reconocimiento de emociones, pero no capturan la complejidad completa de la mentalización, incluyendo la comprensión de intenciones u otros estados mentales p. 6.
3. El estudio no examinó rostros de diversas culturas, edades o tonos de piel, y las imágenes probadas eran en blanco y negro, basadas en poblaciones británicas y francesas. Esto podría limitar la generalización de los hallazgos p. 6.
4. Debido a la naturaleza de ""caja negra"" de estos modelos, es difícil determinar las razones detrás de sus conclusiones y comprender las diferencias entre modelos o iteraciones dentro del mismo modelo p. 6.
5. La interacción con ChatGPT y Bard se realizó únicamente en inglés, mientras que los datos de normas para la comparación se recopilaron de una población general de habla francesa, lo que plantea preocupaciones sobre la precisión y validez de la comparación debido a las diferencias de idioma p. 6.",
34543203,A 10.13µJ/Classification 2-Channel Deep Neural Network Based SoC for Negative Emotion Outburst Detection of Autistic Children,"Aslam AR, Altaf MAB.",2021,,,,,,,,,,"Excluido, no esta en sci-hub"
33518264,"Emerging Evidence for Putative Neural Networks and Antecedents of Pediatric Anxiety in the Fetal, Neonatal, and Infant Periods","Doyle CM, Lasch C, Elison JT.",2021,"Niños, Adolescentes",-,imagen (neuroimagen),"medir la ansiedad y el temperamento ansioso (AT) en el contexto de la ansiedad pediátrica. Port tanto mide es la ansiedad, y los indicadores neuronales, fisiológicos y conductuales asociados se utilizan para proporcionar predicciones a nivel individual del riesgo de ansiedad antes de que surjan o se consoliden síntomas clínicamente significativos  p.1 p.3",-,-,No,"la investigación se centra en la evidencia emergente sobre redes neuronales y antecedentes de ansiedad pediátrica en las primeras etapas del desarrollo. Los principales hallazgos de la investigación incluyen:
1. La naturaleza predictiva imperfecta de los fenotipos conductuales tempranos: el informe destaca que las caracterizaciones actuales de la inhibición conductual (BI) y el miedo desregulado (DF) en la infancia son predictores imperfectos del riesgo de problemas de ansiedad clínicamente procesables, y menos del 50% de los niños con inhibición conductual desarrollan Trastornos de ansiedad en la infancia o adolescencia p. 2.
2. Importancia de las medidas neuronales de riesgo: el informe enfatiza la necesidad de medidas neuronales de riesgo para aumentar la utilidad y el valor predictivo de un perfil de riesgo, aprovechando así múltiples niveles de análisis. Sugiere que acoplar marcadores neuronales con factores conductuales, como BI, mejorará la capacidad de predecir el riesgo de ansiedad a nivel individual específico p.4
3. Papel del momento del desarrollo: El momento de la medición e identificación de los marcadores de riesgo se destaca como vital para identificar si las medidas representan un riesgo de ansiedad futura, enfatizando la importancia de comprender el cerebro en desarrollo en la identificación temprana del riesgo p. 4","1. Naturaleza predictiva imperfecta de los fenotipos conductuales tempranos: el informe destaca que las caracterizaciones actuales de la inhibición conductual (BI) y el miedo desregulado (DF) en la infancia son predictores imperfectos del riesgo de problemas de ansiedad clínicamente procesables, ya que menos del 50% de los niños con inhibiciones conductuales desarrollan ansiedad. Trastornos en la infancia o la adolescencia p. 2 .
2. Falta de sensibilidad y especificidad de las características de BI: la mayoría de los niños que presentan BI no cumplen con los criterios de trastorno de ansiedad social en la edad adulta, en parte debido a la heterogeneidad en la ansiedad pediátrica y la falta de sensibilidad y especificidad de las características de BI. No todos los niños temerosos muestran atipicidad en los índices utilizados para caracterizar BI p. 2 .
3. Desafíos metodológicos en neuroimagen: el informe reconoce que la neuroimagen enfrenta desafíos y limitaciones, como la poca confiabilidad de las tareas de imágenes por resonancia magnética funcional utilizadas anteriormente para medir diversos aspectos de la ansiedad en poblaciones de mayor edad. Sin embargo, los avances en protocolos y tecnología han mejorado las tasas de éxito y se esperan mayores avances metodológicos p. 9",
36072733,A Multimodal Convolutional Neural Network Model for the Analysis of Music Genre on Children's Emotions Influence Intelligence,"Chen W, Wu G.",2022,Niños,red neuronal convolucional (CNN) multimodal,"señales de EEG y datos de movimientos oculares, además los espectrogramas de potencia de audio obtenidos mediante extracción de características se utilizan para la clasificación de géneros musicales. ",las emociones que se están midiendo no se mencionan explícitamente,"DL, redes neuronales","conjunto de datos Million Song Dataset (MSD) para preentrenar la red Dense Inception. Además, se utilizan el conjunto de datos GTZAN y el conjunto de datos ISMIR2004 para entrenar el modelo. ",No,"Desarrollo de un modelo de red neuronal convolucional multimodal para analizar la influencia de los géneros musicales en las emociones de los niños. 
El estudio demuestra que la señal multimodal, que combina señales de EEG y movimientos oculares, logra una mayor precisión en la clasificación de emociones en comparación con las señales unimodales, alcanzando una precisión promedio del 97.94% para la clasificación cuádruple de emociones basada en una señal de EEG de 6 canales y la señal multimodal de los niños. 
Además, el estudio muestra que el preentrenamiento del modelo con el conjunto de datos Million Song Dataset (MSD) mejora significativamente su efectividad, con una precisión de la red Dense Inception alcanzando el 91.0% y el 89.91% en los conjuntos de datos GTZAN e ISMIR2004, respectivamente p. 6",-,
36806017,Coding infant engagement in the Face-to-Face Still-Face paradigm using deep neural networks,"Faltyn M, Krzeczkowski JE, Cummings M, Anwar S, Zeng T, Zahid I, Ntow KO, Van Lieshout RJ.",2023,,,,,,,,,,"Excluido, no esta en sci-hub"
36081739,Research on Mental Health Monitoring Scheme of Migrant Children Based on Convolutional Neural Network Based on Deep Learning,Yang G.,2022,Niños,"redes neuronales convolucionales unidimensionales (1D-CNN) y redes neuronales recurrentes (RNN), tambien menciona el uso de redes de memoria a corto y largo plazo (LSTM)","incluyen datos de consumo, datos de control de acceso, registros de red y datos de calificaciones, es decir, comportamiento en línea de los estudiantes, los patrones dietéticos y el estado psicológico",-,"DL, redes neuronales",-,No,-,-,"Excluido, el artículo fue retractado"
33866302,Combining a parallel 2D CNN with a self-attention Dilated Residual Network for CTC-based discrete speech emotion recognition,"Zhao Z, Li Q, Zhang Z, Cummins N, Wang H, Tao J, W Schuller B.",2021,Niños,"redes neuronales profundas (DNN) y redes neuronales convolucionales (CNN) para el reconocimiento de emociones del habla (SER) p. 2 p  . 3. E incorpora la pérdida de Clasificación Temporal Conexionista (CTC), que es un tipo de red neuronal utilizada para el modelado de secuencias  p. 2  . ",audio,"estados emocionales discretos del habla humana:  Neutral, Feliz, Triste y Enojado  p. 6","DL, redes neuronales","Si, 2. La primera base de datos es el conjunto de datos interactivo de captura de movimiento diádico emocional (IEMOCAP), que contiene grabaciones de datos audiovisuales y transcripciones de diálogos entre dos actores  p. 5 p. 6  . La segunda base de datos utilizada es FAU Aibo Emotion Corpus, que contiene muestras de habla alemana espontánea y emocional obtenidas de niños que interactúan con el robot mascota Aibo de Sony p. 6 ",No,"el desarrollo de una arquitectura de red neuronal profunda eficiente para el reconocimiento discreto de las emociones del habla. El enfoque propuesto demuestra eficacia en el reconocimiento de estados emocionales discretos, logrando una precisión ponderada (WA) del 73,1 % y una precisión no ponderada (UA) del 66,3 % en el conjunto de datos IEMOCAP, así como una UA del 41,1 % en el conjunto de datos FAU-AEC. p. 1 .","la posible pérdida de información temporal al aplicar redes neuronales convolucionales (CNN) a tareas de reconocimiento de emociones del habla (SER), así como el desafío de codificar de manera efectiva relaciones espaciales y aprender representaciones sin perder resoluciones para SER basado en CNN. sistemas  pág. 2  . Además, la velocidad de entrenamiento y la convergencia de redes neuronales recurrentes (RNN), como las redes de memoria a corto plazo (LSTM), se identificaron como limitaciones debido a su naturaleza secuencial y su lenta convergencia durante el entrenamiento  p. 2  .",
35909819,A Multi-Modal Convolutional Neural Network Model for Intelligent Analysis of the Influence of Music Genres on Children's Emotions,"Qian Q, Chen X.",2022,Niños,"propone un modelo de red neuronal convolucional multimodal basado en transformadores. redes neuronales BiLSTM y BERT para extraer características de información de video, audio y texto, y también incluye un módulo de fusión de características de información multimodal basado en el modelo de red transformadora","video, audio y texto","tristeza, emociones normales y optimismo","DL, redes neuronales","conjuntos de datos CMU-MOSI y CMU-MOSE, que contienen clips de vídeo, clips de audio y clips de texto correspondientes de YouTube.",No,"1. El modelo de red neuronal convolucional multimodal basado en transformador propuesto fusiona efectivamente características de video, audio y texto para analizar la influencia de los géneros musicales en las emociones de los niños, superando otros métodos en precisión de predicción y mejorando la precisión de las tareas de clasificación de sentimientos. 
2. El estudio demuestra que el modelo de clasificación de sentimientos logra una mayor precisión y el grado de correlación de las características multimodales muestra una cierta conexión entre el video, el audio y las características del texto correspondiente  p. 6  
3. La investigación indica que la precisión de la predicción del modelo se ve afectada por las características de video y texto, y alinear estas características dentro de un cierto rango puede mejorar significativamente la precisión del modelo  p. 6  
4. El estudio amplía el conjunto de datos de clasificación de sentimientos y recopila continuamente nuevos datos para mejorar la capacidad del modelo de red para aprender y discriminar  p. 7  5. 
5. Se ha demostrado experimentalmente que el modelo propuesto clasifica diferentes tipos de características, incluidos video, audio, texto y ruido aleatorio, y clasifica géneros musicales en 10 categorías  p. 7  . ",-,